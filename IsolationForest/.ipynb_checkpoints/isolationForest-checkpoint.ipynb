{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f239910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ba972ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def byte_decoder(val):\n",
    "    # decodes byte literals to strings\n",
    "    \n",
    "    return val.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fdd437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title, classes=['abnormal', 'normal'],\n",
    "                          cmap=plt.cm.Blues, save=False, saveas=\"MyFigure.png\"):\n",
    "    \n",
    "    # print Confusion matrix with blue gradient colours\n",
    "    \n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.1%'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(saveas, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fddbd020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gridsearch_cv(results, estimator, x_min, x_max, y_min, y_max,save=False, saveas=\"MyFigure.png\"):\n",
    "    \n",
    "    # print GridSearch cross-validation for parameters\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.title(\"GridSearchCV for \"+estimator, fontsize=24)\n",
    "\n",
    "    plt.xlabel(estimator)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.grid()\n",
    "\n",
    "    ax = plt.axes()\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "\n",
    "    pad = 0.005\n",
    "    X_axis = np.array(results[\"param_\"+estimator].data, dtype=float)\n",
    "\n",
    "    for scorer, color in zip(sorted(scoring), ['b', 'k']):\n",
    "        for sample, style in (('train', '--'), ('test', '-')):\n",
    "            sample_score_mean = results['mean_%s_%s' % (sample, scorer)]\n",
    "            sample_score_std = results['std_%s_%s' % (sample, scorer)]\n",
    "            ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n",
    "                        sample_score_mean + sample_score_std,\n",
    "                        alpha=0.1 if sample == 'test' else 0, color=color)\n",
    "            ax.plot(X_axis, sample_score_mean, style, color=color,\n",
    "                alpha=1 if sample == 'test' else 0.7,\n",
    "                label=\"%s (%s)\" % (scorer, sample))\n",
    "\n",
    "        best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n",
    "        best_score = results['mean_test_%s' % scorer][best_index]\n",
    "\n",
    "        # Plot a dotted vertical line at the best score for that scorer marked by x\n",
    "        ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n",
    "            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n",
    "\n",
    "        # Annotate the best score for that scorer\n",
    "        ax.annotate(\"%0.5f\" % best_score,\n",
    "                (X_axis[best_index], best_score+pad))\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid('off')\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(saveas, dpi=100)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = 'target'\n",
    "# sf = datasets.fetch_kddcup99(subset='SF', percent10=False)\n",
    "# dfSF=pd.DataFrame(sf.data, \n",
    "#                   columns=[\"duration\", \"service\", \"src_bytes\", \"dst_bytes\"])\n",
    "# assert len(dfSF)>0, \"SF dataset no loaded.\"\n",
    "\n",
    "# dfSF[target]=sf.target\n",
    "# anomaly_rateSF = 1.0 - len(dfSF.loc[dfSF[target]==b'normal.'])/len(dfSF)\n",
    "\n",
    "# \"SF Anomaly Rate is:\"+\"{:.1%}\".format(anomaly_rateSF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7980508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'target'\n",
    "sa = datasets.fetch_kddcup99(subset='SA', percent10=True)\n",
    "dfSA=pd.DataFrame(sa.data, \n",
    "                  columns=[\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\n",
    "                           \"urgent\",\"hot\",\"num_failed_logins\",\"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\n",
    "                           \"num_root\",\"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\n",
    "                           \"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\n",
    "                           \"same_srv_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "                           \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "                           \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "                           \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\"])\n",
    "assert len(dfSA)>0, \"SA dataset not loaded.\"\n",
    "\n",
    "dfSA[target]=sa.target\n",
    "anomaly_rateSA = 1.0 - len(dfSA.loc[dfSA[target]==b'normal.'])/len(dfSA)\n",
    "\n",
    "\"SA Anomaly Rate is:\"+\"{:.1%}\".format(anomaly_rateSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693741ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f485a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = dfSA.loc[dfSA[target] == b'normal.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db259f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3849d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DATA_PATH = 'C:\\\\Users\\\\Qin\\\\Desktop\\\\kddtrain.csv'\n",
    "# TEST_DATA_PATH = 'C:\\\\Users\\\\Qin\\\\Desktop\\\\kddtest.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5809b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(TRAIN_DATA_PATH)\n",
    "# test_df = pd.read_csv(TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dea27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d37ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anomaly_rateSA = 1.0 - len(train_df.loc[train_df['label']=='normal.'])/len(train_df)\n",
    "# anomaly_rateSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce446caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfSA = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002fdb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2eb611",
   "metadata": {},
   "outputs": [],
   "source": [
    "toDecodeSA = ['protocol_type', 'service', 'flag', target]\n",
    "toDecodeSF = ['service', target]\n",
    "\n",
    "print (\"Original SA Target values:\",set(dfSA[target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc22bc0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bab0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply hot encoding to fields of type string\n",
    "# convert all abnormal target types to single anomaly class\n",
    "\n",
    "# dfSF['binary_target'] = [1 if x==b'normal.' else -1 for x in dfSF[target]]\n",
    "dfSA['binary_target'] = [1 if x==b'normal.' else -1 for x in dfSA[target]]\n",
    "\n",
    "leSA = preprocessing.LabelEncoder()\n",
    "\n",
    "for f in toDecodeSA:\n",
    "    dfSA[f] = list(map(byte_decoder, dfSA[f]))\n",
    "    dfSA[f] = leSA.fit_transform(dfSA[f])\n",
    "    \n",
    "# leSF = preprocessing.LabelEncoder()\n",
    "\n",
    "# for f in toDecodeSF:\n",
    "#     dfSF[f] = list(map(byte_decoder, dfSF[f]))\n",
    "#     dfSF[f] = leSF.fit_transform(dfSF[f])\n",
    "    \n",
    "dfSA_normed = preprocessing.normalize(dfSA.drop([target,'binary_target'], axis=1))\n",
    "# dfSF_normed = preprocessing.normalize(dfSF.drop([target, 'binary_target'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1394d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sa, X_test_sa, y_train_sa, y_test_sa = train_test_split(dfSA.drop([target, 'binary_target'], axis=1), \n",
    "                                                                dfSA['binary_target'], \n",
    "                                                    test_size=0.33, random_state=11)\n",
    "X_train_nd, X_test_nd, y_train_nd, y_test_nd = train_test_split(dfSA_normed, dfSA['binary_target'], \n",
    "                                                    test_size=0.33, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb3f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36bc55b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手动添加特征，训练集42，测试集41\n",
    "\n",
    "feather = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', \n",
    "           'num_failed_logins', 'logged_in', 'lnum_compromised', 'lroot_shell', 'lsu_attempted', 'lnum_root', 'lnum_file_creations', \n",
    "           'lnum_shells', 'lnum_access_files', 'lnum_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', \n",
    "           'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', \n",
    "           'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', \n",
    "           'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b9295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DATA_PATH = 'C:\\\\Users\\\\Qin\\\\Desktop\\\\UNSW-NB 15\\\\UNSW_NB15_training-set.csv'\n",
    "TRAIN_DATA_PATH = 'C:\\\\Users\\\\Qin\\\\Desktop\\\\kddcup\\\\train_10_percent_kddcup.csv'\n",
    "TEST_DATA_PATH = 'C:\\\\Users\\\\Qin\\\\Desktop\\\\kddcup\\\\test_10_percent_kddcup.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e4b968e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Qin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3166: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_DATA_PATH, header = None, names = feather)\n",
    "test_df = pd.read_csv(TEST_DATA_PATH, header = None, names = feather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "966b2f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['label'] == 0]\n",
    "y_label = test_df.iloc[ : , 41 : 42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0836020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除所有分类列\n",
    "train_df.drop(['protocol_type', 'service', 'flag', 'land', 'logged_in', 'is_host_login', 'is_guest_login', 'label'], axis = 1, inplace = True)\n",
    "# 删除无标准偏差的列\n",
    "train_df.drop(['wrong_fragment', 'urgent', 'num_failed_logins', 'lsu_attempted', 'lnum_file_creations', 'lnum_outbound_cmds'], axis = 1, inplace = True)\n",
    "\n",
    "# 删除所有分类列\n",
    "test_df.drop(['protocol_type', 'service', 'flag', 'land', 'logged_in', 'is_host_login', 'is_guest_login', 'label'], axis = 1, inplace = True)\n",
    "# 删除无标准偏差的列\n",
    "test_df.drop(['wrong_fragment', 'urgent', 'num_failed_logins', 'lsu_attempted', 'lnum_file_creations', 'lnum_outbound_cmds'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c6da4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = pd.Series([0 if i == 0 else 1 for i in y_label['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60cf00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d82d7a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfIF = IsolationForest(max_samples=0.25, random_state=11, n_estimators=100, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d3ed834f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Qin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time :  1.579420800000662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Qin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "clfIF.fit(train_df)\n",
    "end = time.clock()\n",
    "print('Time : ', (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9aeb2a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Qin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time :  14.412569699999949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Qin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "y_pred_if = clfIF.predict(test_df)\n",
    "end = time.clock()\n",
    "print('Time : ', (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3dfb63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for i in range(0, len(y_pred_if)) :\n",
    "    if y_pred_if[i] == 1 :\n",
    "        y_pred_if[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d0fbde72",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for i in range(0, len(y_pred_if)) :\n",
    "    if y_pred_if[i] == -1 :\n",
    "        y_pred_if[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "baa13007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Precision = 0.99542\n",
      " Recall    = 0.77737\n",
      " F1-Score  = 0.87298\n",
      " AUC  = 0.88129\n"
     ]
    }
   ],
   "source": [
    "prec, recall, fscore, _ = precision_recall_fscore_support(y_labels, y_pred_if, average=\"binary\")\n",
    "auc = roc_auc_score(y_labels, y_pred_if)\n",
    "print(f\" Precision = {prec:.5f}\")\n",
    "print(f\" Recall    = {recall:.5f}\")\n",
    "print(f\" F1-Score  = {fscore:.5f}\")\n",
    "print(f\" AUC  = {auc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d68685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af45c965",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfLOF = LocalOutlierFactor(n_neighbors=15, metric='euclidean', algorithm='auto', contamination=0.15, n_jobs=-1, novelty = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f8a4dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Qin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time :  426.332649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Qin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "y_pred_lof = clfLOF.fit(train_df)\n",
    "end = time.clock()\n",
    "print('Time : ', (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1461eda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Qin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time :  1177.2337388999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Qin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "y_pred_lof = clfLOF.predict(test_df)\n",
    "end = time.clock()\n",
    "print('Time : ', (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "366ee01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = y_pred_lof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d022bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for i in range(0, len(y_pred_lof)) :\n",
    "    if y_pred_lof[i] == 1 :\n",
    "        y_pred_lof[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "567538b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for i in range(0, len(y_pred_lof)) :\n",
    "    if y_pred_lof[i] == -1 :\n",
    "        y_pred_lof[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c9815127",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Precision = 0.93901\n",
      " Recall    = 0.94609\n",
      " F1-Score  = 0.94254\n",
      " AUC  = 0.84605\n"
     ]
    }
   ],
   "source": [
    "prec, recall, fscore, _ = precision_recall_fscore_support(y_labels, y_pred_lof, average=\"binary\")\n",
    "auc = roc_auc_score(y_labels, y_pred_lof)\n",
    "print(f\" Precision = {prec:.5f}\")\n",
    "print(f\" Recall    = {recall:.5f}\")\n",
    "print(f\" F1-Score  = {fscore:.5f}\")\n",
    "print(f\" AUC  = {auc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba304ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8e1c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2c2e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_label, y_pred_if, target_names=['anomaly', 'normal']))\n",
    "# print (\"AUC: \", \"{:.5%}\".format(roc_auc_score(y_label, y_pred_if)))\n",
    "cm = confusion_matrix(y_label, y_pred_if)\n",
    "plot_confusion_matrix(cm, title=\"IF Confusion Matrix - SA\", save=True, saveas=\"IF_SA.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_nd, y_pred_train_lof, target_names=['anomaly', 'normal']))\n",
    "print (\"AUC: \", \"{:.1%}\".format(roc_auc_score(y_train_nd, y_pred_train_lof)))\n",
    "cm = confusion_matrix(y_train_nd, y_pred_train_lof)\n",
    "plot_confusion_matrix(cm, title=\"LOF Confusion Matrix - SA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ddf09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_sf, X_test_sf, y_train_sf, y_test_sf = train_test_split(dfSF.drop([target, 'binary_target'], axis=1), \n",
    "#                                                                 dfSF['binary_target'], test_size=0.33, random_state=11)\n",
    "# X_train_nd, X_test_nd, y_train_nd, y_test_nd = train_test_split(dfSF_normed, dfSF['binary_target'], \n",
    "#                                                     test_size=0.33, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1185a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clfIF = IsolationForest(max_samples=0.25, random_state=11, contamination = 0.15, n_estimators=100, n_jobs=-1)\n",
    "# clfLOF = LocalOutlierFactor(n_neighbors=15, metric='euclidean', algorithm = 'auto', contamination=0.15, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de47bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = datetime.datetime.now()\n",
    "# clfIF.fit(X_train_sf,y_train_sf)\n",
    "# y_pred_train = clfIF.predict(X_train_sf)\n",
    "# end = datetime.datetime.now()\n",
    "# print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f310e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = datetime.datetime.now()\n",
    "# y_pred_train_lof = clfLOF.fit_predict(X_train_nd,y_train_nd)\n",
    "# end = datetime.datetime.now()\n",
    "# print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cdf438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_train_sf, y_pred_train, target_names=['anomaly', 'normal']))\n",
    "# print (\"AUC: \", \"{:.1%}\".format(roc_auc_score(y_train_sf, y_pred_train)))\n",
    "# cm = confusion_matrix(y_train_sf, y_pred_train)\n",
    "# plot_confusion_matrix(cm, title=\"IF Confusion Matrix - SF\", save=True, saveas=\"IF_SF.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe31f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_train_nd, y_pred_train_lof, target_names=['anomaly', 'normal']))\n",
    "# print (\"AUC: \", \"{:.1%}\".format(roc_auc_score(y_train_nd, y_pred_train_lof)))\n",
    "# cm = confusion_matrix(y_train_nd, y_pred_train_lof)\n",
    "# plot_confusion_matrix(cm, title=\"LOF Confusion Matrix - SF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f6853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ceada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfIF = IsolationForest(max_samples=0.25, random_state=11, contamination = 0.15, n_estimators=100, n_jobs=-1)\n",
    "\n",
    "clfIF.fit(X_train_sa,y_train_sa)\n",
    "y_pred_test = clfIF.predict(X_test_sa)\n",
    "\n",
    "print(classification_report(y_test_sa, y_pred_test, target_names=['anomaly', 'normal']))\n",
    "print (\"AUC: \", \"{:.1%}\".format(roc_auc_score(y_test_sa, y_pred_test)))\n",
    "cm = confusion_matrix(y_test_sa, y_pred_test)\n",
    "plot_confusion_matrix(cm, title=\"IF Confusion Matrix - SA\", save=True, saveas=\"IF_SA_Test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454980b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clfIF = IsolationForest(max_samples=0.25, random_state=11, contamination = 0.15, n_estimators=100, n_jobs=-1)\n",
    "\n",
    "# clfIF.fit(X_train_sf,y_train_sf)\n",
    "# y_pred_test = clfIF.predict(X_test_sf)\n",
    "\n",
    "# print(classification_report(y_test_sf, y_pred_test, target_names=['anomaly', 'normal']))\n",
    "# print (\"AUC: \", \"{:.1%}\".format(roc_auc_score(y_test_sf, y_pred_test)))\n",
    "# cm = confusion_matrix(y_test_sf, y_pred_test)\n",
    "# plot_confusion_matrix(cm, title=\"IF Confusion Matrix - SF\", save=True, saveas=\"IF_SF_Test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48491b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12208ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'AUC': 'roc_auc', 'Recall': make_scorer(recall_score, pos_label=-1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dbfaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(IsolationForest(max_samples=0.25, random_state=11, contamination = 0.15, n_jobs=-1),\n",
    "                  param_grid={'n_estimators': range(20, 230, 30)},\n",
    "                  scoring=scoring, refit='Recall')\n",
    "gs.fit(X_train_sa, y_train_sa)\n",
    "results = gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e490c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gridsearch_cv(results, \"n_estimators\", 0, 230, 0.73, 1.05, save=True, saveas=\"GS_n_est.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab61576c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14130c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_ms = GridSearchCV(IsolationForest(random_state=11, contamination = 0.15, n_estimators=150, n_jobs=-1),\n",
    "                  param_grid={'max_samples': np.arange(0.1, 1.0, 0.1)},\n",
    "                  scoring=scoring, refit='Recall')\n",
    "gs_ms.fit(X_train_sa, y_train_sa)\n",
    "results = gs_ms.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c6ffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gridsearch_cv(results, \"max_samples\", 0, 1, 0.73, 1.05, save=True, saveas=\"GS_max_samples.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e0e068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feda77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_cont = GridSearchCV(IsolationForest(random_state=11, max_samples=0.10, n_estimators=150, n_jobs=-1),\n",
    "                  param_grid={'contamination': np.arange(0.01, 0.25, 0.05)},\n",
    "                  scoring=scoring, refit='Recall')\n",
    "gs_cont.fit(X_train_sf, y_train_sf)\n",
    "results = gs_cont.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da5fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gridsearch_cv(results, \"contamination\", 0, 0.20, 0.80, 1.08, save=True, saveas=\"GS_cont.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf9596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
